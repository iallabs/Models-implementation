import tensorflow as tf
import os
import sys
import math

#Step : Sentence Segmentation


#Step : Word Tokenization

#Step : Text Lemmatization (retrieve the base form of each word)



#Step : Encode into text record





#General step: Use tf.Dataset text functions to process text directly
#into our graph